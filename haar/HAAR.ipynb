{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a874237-7d35-4ea2-84b4-f1457fc9ede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.6)\n",
      "Requirement already satisfied: pillow in c:\\users\\asus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (11.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-contrib-python numpy pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6acc1ed5-ced3-4371-a4a3-bd95156c3559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo entrenado y guardado como 'trainer.yml'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Ruta al dataset\n",
    "path = 'dataset'\n",
    "\n",
    "# Crear el reconocedor LBPH\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Cargar el clasificador Haar Cascade\n",
    "detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Función para obtener imágenes y etiquetas\n",
    "def get_images_and_labels(path):\n",
    "    face_samples = []\n",
    "    ids = []\n",
    "    \n",
    "    # Recorrer cada carpeta de persona en el dataset\n",
    "    for person_folder in os.listdir(path):\n",
    "        # Ignorar carpetas que no sean de personas (como .ipynb_checkpoints)\n",
    "        if person_folder == '.ipynb_checkpoints':\n",
    "            continue\n",
    "            \n",
    "        person_path = os.path.join(path, person_folder)\n",
    "        if not os.path.isdir(person_path):\n",
    "            continue\n",
    "            \n",
    "        # Obtener el ID de la persona (usamos el nombre de la carpeta como ID)\n",
    "        try:\n",
    "            person_id = int(person_folder)\n",
    "        except ValueError:\n",
    "            continue  # Si el nombre no es un número, lo saltamos\n",
    "            \n",
    "        # Recorrer cada imagen en la carpeta de la persona\n",
    "        for image_name in os.listdir(person_path):\n",
    "            image_path = os.path.join(person_path, image_name)\n",
    "            \n",
    "            # Verificar que sea un archivo de imagen (por extensión)\n",
    "            if not (image_name.lower().endswith(('.png', '.jpg', '.jpeg'))):\n",
    "                continue\n",
    "                \n",
    "            # Convertir a escala de grises\n",
    "            pil_image = Image.open(image_path).convert('L')\n",
    "            img_numpy = np.array(pil_image, 'uint8')\n",
    "            \n",
    "            # Detectar rostros\n",
    "            faces = detector.detectMultiScale(img_numpy)\n",
    "            \n",
    "            for (x, y, w, h) in faces:\n",
    "                face_samples.append(img_numpy[y:y+h, x:x+w])\n",
    "                ids.append(person_id)\n",
    "    \n",
    "    return face_samples, ids\n",
    "\n",
    "# Obtener datos de entrenamiento\n",
    "faces, ids = get_images_and_labels(path)\n",
    "\n",
    "# Entrenar el modelo\n",
    "recognizer.train(faces, np.array(ids))\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "recognizer.write('trainer.yml')\n",
    "print(\"Modelo entrenado y guardado como 'trainer.yml'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "452bf219-9785-4b2a-bad7-1c384859f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Cargar el clasificador Haar Cascade\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Cargar el modelo LBPH entrenado\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('trainer.yml')\n",
    "\n",
    "# Diccionario de nombres (debe coincidir con los IDs del entrenamiento)\n",
    "names = {1: \"Persona1\", 2: \"Persona2\"}  # Ajusta según tus IDs\n",
    "\n",
    "# Inicializar la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detectar rostros con Haar Cascade\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        # Dibujar rectángulo\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Predecir quién es con LBPH\n",
    "        id, confidence = recognizer.predict(gray[y:y+h, x:x+w])\n",
    "        \n",
    "        # Verificar confianza (menor es mejor)\n",
    "        if confidence < 100:\n",
    "            name = names.get(id, \"Desconocido\")\n",
    "            confidence_text = f\"{round(100 - confidence)}%\"\n",
    "        else:\n",
    "            name = \"Desconocido\"\n",
    "            confidence_text = f\"{round(100 - confidence)}%\"\n",
    "        \n",
    "        # Mostrar nombre y confianza\n",
    "        cv2.putText(frame, f\"{name} {confidence_text}\", (x+5, y-5), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    \n",
    "    # Mostrar imagen\n",
    "    cv2.imshow('Reconocimiento Facial', frame)\n",
    "    \n",
    "    # Salir con 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faee6117-75f6-4bfa-a277-20d21c848973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
